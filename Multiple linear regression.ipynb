{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d90cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea808be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('50_Startups.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d53cf863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Create a ColumnTransformer to one-hot encode the categorical column (column 3)\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[('encoder', OneHotEncoder(), [3])],  # Specify the column index to be one-hot encoded\n",
    "    remainder='passthrough'  # Pass through all other columns\n",
    ")\n",
    "\n",
    "X = np.array(ct.fit_transform(X))  # Transform and replace the original X with one-hot encoded values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5125041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoiding the Dummy Variable Trap\n",
    "X = X[:, 1:] # take all columns from 1 on (drop first column)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "500a1792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "# Reshape y_train into a 2D array-like format\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e52df347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "079f6550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Values (y_pred):  [[-0.15893089]\n",
      " [ 0.57173963]\n",
      " [ 0.56841486]\n",
      " [-0.92597858]\n",
      " [ 1.70739852]\n",
      " [ 0.16593804]\n",
      " [-1.02790215]\n",
      " [-0.2633025 ]\n",
      " [ 0.11177345]\n",
      " [ 1.44504243]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print(\"Predicted Values (y_pred): \", y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
